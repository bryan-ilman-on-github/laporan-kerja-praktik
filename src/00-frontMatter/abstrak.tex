\chapter*{Abstrak}
\singlespacing

\noindent \begin{tabular}{l l p{10cm}}
	\ifx\blank\npmDua
		Nama&: & \penulisSatu \\
		Program Studi&: & \programSatu \\
	\else
		Nama Penulis 1 / Program Studi&: & \penulisSatu~/ \programSatu\\
		Nama Penulis 2 / Program Studi&: & \penulisDua~/ \programDua\\
	\fi
	\ifx\blank\npmTiga\else
		Nama Penulis 3 / Program Studi&: & \penulisTiga~/ \programTiga\\
	\fi
	Judul&: & \judul \\
	Pembimbing&: & \pembimbingSatu \\
	\ifx\blank\pembimbingDua
    \else
        \ &\ & \pembimbingDua \\
    \fi
    \ifx\blank\pembimbingTiga
    \else
    	\ &\ & \pembimbingTiga \\
    \fi
\end{tabular} \\

\vspace*{0.5cm}

\noindent \textit{Streaming data} secara \textit{real-time} merupakan proses pengiriman data secara kontinu dari sumber ke penerima, yang sering digunakan dalam aplikasi yang membutuhkan respons cepat dan aliran data besar. Apache Kafka adalah platform yang digunakan untuk mengelola proses ini, di mana data dipartisi menjadi topik untuk memungkinkan pemrosesan paralel oleh berbagai konsumen. Kerja praktik ini berfokus pada penelitian optimisasi partisi topik Apache Kafka, sebagaimana dijelaskan dalam paper berjudul ``Efficient Topic Partitioning of Apache Kafka for High-Reliability Real-Time Data Streaming Applications''. Pelaksana kerja praktik berperan sebagai \textit{Research Assistant} di Computer Systems Laboratory (CSL) Fakultas Ilmu Komputer Universitas Indonesia, sebuah laboratorium yang fokus pada penelitian komputasi kinerja tinggi dan manajemen big data. Tugas utamanya adalah menjalankan eksperimen \textit{end-to-end}, yang dalam konteks ini berarti mengamati aliran data dari produser hingga konsumen untuk mengukur latensi dari di seluruh proses. Metodologi yang digunakan dalam kerja praktik ini mencakup beberapa langkah penting. Di awal, pelaksana menyiapkan VM di Google Cloud Platform (GCP) dan menginstal semua dependensi yang dibutuhkan untuk eksperimen Kafka. Setelah itu, eksperimen dijalankan dengan satu VM yang bertindak sebagai klien Kafka dan satu lagi sebagai kluster Kafka. Eksperimen difokuskan pada pengujian algoritma BroMax dan BroMin untuk memantau perilaku partisi topik. Algoritma tersebut digunakan untuk secara matematis menentukan jumlah partisi yang optimal demi mencapai \textit{throughput} maksimal. Selain itu, resource monitoring dilakukan secara rutin untuk melacak penggunaan CPU, RAM, dan \textit{disk space} pada VM. Eksperimen lalu diulang pada infrastruktur UI (DGX dan BMKGCS), termasuk eksplorasi penggunaan Docker-in-Docker untuk menjalankan eksperimen tanpa akses root. Metodologi Scrum diterapkan dalam proyek ini dengan siklus \textit{sprint} dua minggu. Hasil dari penelitian ini membantu kita memahami perilaku \textit{latency} dan \textit{throughput} pada berbagai \textit{application constraints}. \\

\vspace*{0.2cm}

\noindent Kata kunci: \\ \f{Fog Computing}, \f{Data Streaming}, \f{Topic Partitioning}, \f{Distributed Systems} \\

\setstretch{1.4}
\newpage
