\chapter*{Abstrak}
\singlespacing

\noindent \begin{tabular}{l l p{10cm}}
	\ifx\blank\npmDua
		Nama&: & \penulisSatu \\
		Program Studi&: & \programSatu \\
	\else
		Nama Penulis 1 / Program Studi&: & \penulisSatu~/ \programSatu\\
		Nama Penulis 2 / Program Studi&: & \penulisDua~/ \programDua\\
	\fi
	\ifx\blank\npmTiga\else
		Nama Penulis 3 / Program Studi&: & \penulisTiga~/ \programTiga\\
	\fi
	Judul&: & \judul \\
	Pembimbing&: & \pembimbingSatu \\
	\ifx\blank\pembimbingDua
    \else
        \ &\ & \pembimbingDua \\
    \fi
    \ifx\blank\pembimbingTiga
    \else
    	\ &\ & \pembimbingTiga \\
    \fi
\end{tabular} \\

\vspace*{0.5cm}

\noindent \textit{Streaming data} secara \textit{real-time} adalah pengiriman data kontinu dari sumber ke penerima, sering digunakan dalam aplikasi yang memerlukan respons cepat dan aliran data besar. Apache Kafka mengelola proses ini dengan mempartisi data menjadi topik untuk pemrosesan paralel. Kerja praktik ini berfokus pada penelitian optimisasi partisi topik Apache Kafka, sebagaimana dijelaskan dalam paper berjudul ``Efficient Topic Partitioning of Apache Kafka for High-Reliability Real-Time Data Streaming Applications''. Pelaksana kerja praktik berperan sebagai \textit{Research Assistant} di Computer Systems Laboratory (CSL) Fakultas Ilmu Komputer Universitas Indonesia, sebuah laboratorium yang fokus pada penelitian komputasi kinerja tinggi dan manajemen \textit{big data}. Tugas utamanya adalah menjalankan eksperimen \textit{end-to-end}, yang dalam konteks ini berarti mengamati aliran data dari produser hingga konsumen untuk mengukur latensi dari di seluruh proses. Metodologi yang digunakan dalam kerja praktik ini mencakup beberapa langkah penting. Di awal, pelaksana menyiapkan VM di Google Cloud Platform dan menginstal semua dependensi yang dibutuhkan untuk eksperimen Kafka. Setelah itu, eksperimen dijalankan dengan satu VM yang bertindak sebagai klien Kafka dan satu lagi sebagai klaster Kafka. Eksperimen difokuskan pada pengujian algoritma BroMax dan BroMin untuk memantau perilaku partisi topik. Algoritma tersebut digunakan untuk secara matematis menentukan jumlah partisi yang optimal demi mencapai \textit{throughput} maksimal. Selain itu, \textit{resource monitoring} dilakukan secara rutin untuk melacak penggunaan CPU, RAM, dan \textit{disk space} pada VM. Eksperimen lalu diulang pada infrastruktur UI. Metodologi eksperimental kuantitatif diterapkan dalam proyek ini, menggunakan berbagai teknologi termasuk Apache Kafka untuk streaming data, Docker dan Linux untuk containerization, serta Google Cloud Platform untuk infrastruktur. Selain itu, Python dan Bash digunakan dalam automasi proses eksperimen. Hasil penelitian ini mencakup pengembangan \textit{framework} berbasis \textit{containerization} yang mengotomatisasi proses \textit{experiment setup} sehingga mempermudah pengujian tanpa perlu konfigurasi manual, dan pemahaman mendalam tentang perilaku \textit{latency} dan \textit{throughput} di bawah berbagai \textit{application constraints}. \\

\vspace*{0.2cm}

\noindent Kata kunci: \\ \f{Fog Computing}, \f{Data Streaming}, \f{Topic Partitioning}, \f{Distributed Systems} \\

\setstretch{1.4}
\newpage
